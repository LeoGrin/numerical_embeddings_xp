{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#df = pd.read_csv(\"all_results_sort_26_02_2.csv\")\n",
    "#df = pd.read_csv(\"all_results_median_rank_28_02.csv\")\n",
    "#df = pd.read_csv(\"all_results_sum_28_02.csv\")\n",
    "#df = pd.read_csv(\"all_results_gaussian_sort_19_03.csv\")\n",
    "# df = pd.read_csv(\"results_summarised/all_results_gaussian_sort_02_04.csv\")\n",
    "# old_df = pd.read_csv(\"results_summarised/all_results_gaussian_sort_19_03.csv\")\n",
    "# old_df[\"old\"]=1\n",
    "# df[\"old\"]=0\n",
    "# df = pd.concat([df, old_df], ignore_index=True)\n",
    "# df = pd.concat([df, pd.read_csv(\"results_summarised/all_results_sort_ff_02_04.csv\")])\n",
    "# df = pd.concat([df, pd.read_csv(\"results_summarised/all_results_sort_26_02_2.csv\")])\n",
    "# df = pd.concat([pd.read_csv(\"results_summarised/all_results_sort_with_holes_03_04.csv\"),\n",
    "#                 pd.read_csv(\"results_summarised/all_results_sort_04_04.csv\")])\n",
    "#df = pd.read_csv(\"results_summarised/all_results_normalization_08_04.csv\")\n",
    "\n",
    "#df = pd.concat([pd.read_csv(\"results_summarised/all_results_sort_08_04_revert.csv\"),\n",
    "#                pd.read_csv(\"results_summarised/all_results_sort_06_04_full.csv\")])\n",
    "#df  = pd.read_csv(\"results_summarised/all_results_sort_06_04_full.csv\")\n",
    "#df  = pd.read_csv(\"results_summarised/all_new_results_sort_14_05_full.csv\")\n",
    "df  = pd.read_csv(\"results_summarised/sort_different_depth_17_05_2.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame and 'test_loss_list' is the column you're working with.\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        # Try to evaluate the row as a literal.\n",
    "        pd.eval(row['test_loss_list'])\n",
    "    except Exception as e:\n",
    "        # If an exception occurs, print the index and the value that failed\n",
    "        print(f\"Failed at index {index}: {row['test_loss_list']}\")\n",
    "        print(f\"Error: {e}\")\n",
    "        # Optionally, break after the first failure\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "# replace \"nan\" with None\n",
    "df['test_loss_list'] = df['test_loss_list'].str.replace('nan', 'None')\n",
    "df['loss_list'] = df['loss_list'].str.replace('nan', 'None')\n",
    "#df['test_loss_list'] = df['test_loss_list'].apply(lambda s: pd.eval(s))\n",
    "#df['loss_list'] = df['loss_list'].apply(lambda s: pd.eval(s))\n",
    "\n",
    "df['test_loss_list'] = df['test_loss_list'].apply(ast.literal_eval)\n",
    "df['loss_list'] = df['loss_list'].apply(ast.literal_eval)\n",
    "\n",
    "# Create a new DataFrame for Plotly Express\n",
    "rows_list = []\n",
    "for _, row in df.iterrows():\n",
    "    params = row.to_dict()\n",
    "    test_loss_list = params.pop('test_loss_list')\n",
    "    loss_list = params.pop('loss_list')\n",
    "    for epoch, loss in enumerate(test_loss_list):\n",
    "        params['epoch'] = epoch\n",
    "        params['test_loss'] = loss\n",
    "        params['train_loss'] = loss_list[epoch]\n",
    "        rows_list.append(params.copy())  # Use .copy() to avoid modifying the original params\n",
    "\n",
    "# Create a new DataFrame\n",
    "df_long = pd.DataFrame(rows_list)\n",
    "df_long = df_long.fillna(\"missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make embedding_function \"gaussian\" or \"none\"\n",
    "\n",
    "def convert_embedding(name):\n",
    "    if \"GaussianEmbedder\" in name:\n",
    "        return \"gaussian\"\n",
    "    elif \"PositionalEncoding\" in name:\n",
    "        return \"positional\"\n",
    "    elif \"RandomFeature\" in name:\n",
    "        return \"fourier\"\n",
    "    else:\n",
    "        return \"none\"\n",
    "df_long[\"embedding\"] = df_long[\"embedding_function\"].apply(convert_embedding)\n",
    "\n",
    "# remove Unnamed: 0\n",
    "df_long = df_long.drop(columns=[\"Unnamed: 0\", \"job_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average over iter\n",
    "# fill na with \"missing\"\n",
    "df_long = df_long.fillna(\"missing\")\n",
    "# convert all to string except test_loss\n",
    "# removing rows where test_loss is missing\n",
    "df_long = df_long[df_long[\"test_loss\"] != \"missing\"]\n",
    "# same for epoch\n",
    "df_long = df_long[df_long[\"epoch\"] != \"missing\"]\n",
    "df_long = df_long.applymap(str)\n",
    "df_long[\"test_loss\"] = df_long[\"test_loss\"].astype(float)\n",
    "df_long[\"epoch\"] = df_long[\"epoch\"].astype(int)\n",
    "df_long[\"train_loss\"] = df_long[\"train_loss\"].astype(float)\n",
    "cols = list(df_long.columns)\n",
    "# # remove iter and test_loss\n",
    "cols.remove(\"iter\")\n",
    "cols.remove(\"test_loss\")\n",
    "cols.remove(\"train_loss\")\n",
    "# check that we have 5 rows for each combination of the other columns\n",
    "#assert all(df_long.groupby(cols).size() > 5)\n",
    "#show groups with less than 5\n",
    "#df_long.groupby(cols).size().sort_values()\n",
    "#df_long = df_long.groupby(cols)[\"test_loss\"].mean().reset_index()\n",
    "# #add a column for the number of rows and the mean test_loss\n",
    "# df_long = df_long.groupby(cols).agg(\n",
    "#     test_loss=('test_loss', 'median'),  # Calculate mean test_loss\n",
    "#     train_loss=('train_loss', 'median'),  # Calculate mean test_loss\n",
    "#     count=('test_loss', 'count'),           # Count the number of entries used for the mean\n",
    "#     std=('test_loss', 'std')\n",
    "# ).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "filter_dic = {\n",
    "    \"n_layer\": 8,\n",
    "    \"n_head\": 4,\n",
    "    \"lr\": 1e-4,\n",
    "    #\"embedding\": \"none\",\n",
    "    #\"lr\": 1e-4,\n",
    "    #\"task\": \"sort_with_holes\",\n",
    "    \"task\": \"sort\",\n",
    "    \"seq_length\": 10,\n",
    "    #\"n_embd\": 128,\n",
    "    #\"read_in_bias\": False,\n",
    "    \"attention_only\": True,\n",
    "    #\"revert_embedding\": True,\n",
    "    #\"parametrize_std\": False,\n",
    "    #\"n_epochs\": 130,\n",
    "    #\"n_epochs\": 300,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "df_plot = df_long.copy()\n",
    "for key, value in filter_dic.items():\n",
    "    df_plot = df_plot[np.isin(df_plot[key], [value, \"missing\"])]\n",
    "\n",
    "print(len(df_plot))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long[\"revert_embedding\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_plot = df_plot[(df_plot[\"iter\"] == \"4\") & (df_plot[\"embedding\"] == \"gaussian\")]\n",
    "df_plot = df_plot[df_plot[\"embedding\"] != \"positional\"]\n",
    "# remove embedding_function\n",
    "#df_plot = df_plot.drop(columns=[\"embedding_function\"])\n",
    "\n",
    "# replace length_scale by the bandwidth column when length_scale is missing\n",
    "# if length_scale column do not exist, first create it\n",
    "if 'length_scale' not in df_plot.columns:\n",
    "    df_plot['length_scale'] = 'missing'\n",
    "#df_plot['length_scale'] = df_plot['length_scale'].replace('missing', pd.NA).fillna(df['bandwidth'])\n",
    "#df_plot.reset_index(drop=True, inplace=True)\n",
    "mask = df_plot['length_scale'] == 'missing'\n",
    "\n",
    "\n",
    "# Replace 'missing' values in 'length_scale' with the corresponding value from 'bandwidth'\n",
    "df_plot.loc[mask, 'length_scale'] = df_plot.loc[mask, 'bandwidth']\n",
    "\n",
    "df_plot[\"embedding_kernel_length\"] = df_plot[\"embedding\"] + \" \" + df_plot[\"kernel\"] + \" \" + df_plot[\"length_scale\"]\n",
    "\n",
    "#df_plot = df_plot[df_plot[\"epoch\"] < 101]\n",
    "#df_plot = df_plot[df_plot[\"count\"] >= 5]\n",
    "#df_plot = df_plot[np.isin(df_plot[\"seq_length\"], [\"3\", \"5\", \"7\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "df_box = df_plot.copy()\n",
    "#df_box = df_box[df_box[\"epoch\"] == 299]\n",
    "#df_box = df_box[df_box[\"embedding\"] == \"none\"]\n",
    "#df_box = df_box[np.isin(df_box[\"length_scale\"], [\"[1.0]\", \"[2.0]\"])]\n",
    "fig = px.scatter(\n",
    "    df_box,\n",
    "    y = \"test_loss\",\n",
    "    x ='epoch',\n",
    "    log_y=True,\n",
    "    color='embedding_kernel_length',\n",
    "    hover_data=df_plot.columns,\n",
    "    #facet_row=\"length_scale\",\n",
    "    #facet_row=\"holes\",\n",
    "    #facet_row=\"parametrize_std\",\n",
    "    height=1500,\n",
    "    # set order on holes\n",
    "    #category_orders={\"holes\": [\"{}\", \"[(0, 1), (2, 3), (4, 5), (6, 7), (8, 9)]\", \"[(3, 7)]\"]},\n",
    "    # show std\n",
    "    #error_y=\"std\",\n",
    "    # transparent\n",
    "\n",
    "    # don't share y-axes\n",
    "\n",
    "    \n",
    "    #facet_row=\"seq_length\",\n",
    "    # limit x to 100\n",
    "    #facet_row=\"attention_only\",\n",
    "    #title=f\"n_layer={filter_dic['n_layer']}, n_head={filter_dic['n_head']}, lr={filter_dic['lr']}, n_embd={filter_dic['n_embd']}\",\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()\n",
    "# log scale on y-axis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "df_box = df_plot.copy()\n",
    "#df_box = df_box[df_box[\"epoch\"] == 299]\n",
    "#df_box = df_box[df_box[\"holes\"] == \"missing\"]\n",
    "#df_box = df_box[np.isin(df_box[\"length_scale\"], [\"[1.0]\", \"[2.0]\"])]\n",
    "df_box[\"rmse_test\"] = np.sqrt(df_box[\"test_loss\"])\n",
    "fig = px.scatter(\n",
    "    df_box,\n",
    "    y = \"rmse_test\",\n",
    "    x ='epoch',\n",
    "    log_y=True,\n",
    "    color='embedding_kernel_length',\n",
    "    hover_data=df_plot.columns,\n",
    "    #facet_row=\"length_scale\",\n",
    "    #facet_row=\"holes\",\n",
    "    #facet_row=\"parametrize_std\",\n",
    "    height=1500,\n",
    "    # set order on holes\n",
    "    #category_orders={\"holes\": [\"{}\", \"[(0, 1), (2, 3), (4, 5), (6, 7), (8, 9)]\", \"[(3, 7)]\"]},\n",
    "    # show std\n",
    "    #error_y=\"std\",\n",
    "    # transparent\n",
    "\n",
    "    # don't share y-axes\n",
    "\n",
    "    \n",
    "    #facet_row=\"seq_length\",\n",
    "    # limit x to 100\n",
    "    #facet_row=\"attention_only\",\n",
    "    #title=f\"n_layer={filter_dic['n_layer']}, n_head={filter_dic['n_head']}, lr={filter_dic['lr']}, n_embd={filter_dic['n_embd']}\",\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()\n",
    "# log scale on y-axis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_box[\"parametrize_std\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "df_box = df_plot.copy()\n",
    "df_box = df_box[df_box[\"epoch\"] == 100]\n",
    "#df_box = df_box[np.isin(df_box[\"length_scale\"], [\"[1.0]\", \"[2.0]\"])]\n",
    "fig = px.box(\n",
    "    df_box,\n",
    "    y = \"embedding_kernel_length\",\n",
    "    x ='test_loss',\n",
    "    log_x=True,\n",
    "    color='embedding',\n",
    "    hover_data=df_plot.columns,\n",
    "    #facet_row=\"length_scale\",\n",
    "    facet_row=\"n_embd\",\n",
    "    facet_col=\"parametrize_std\",\n",
    "    #facet_row=\"parametrize_std\",\n",
    "    height=1500,\n",
    "    # set order on holes\n",
    "    category_orders={\"holes\": [\"{}\", \"[(0, 1), (2, 3), (4, 5), (6, 7), (8, 9)]\", \"[(3, 7)]\"]},\n",
    "    # show std\n",
    "    #error_y=\"std\",\n",
    "    # transparent\n",
    "\n",
    "    # don't share y-axes\n",
    "\n",
    "    \n",
    "    #facet_row=\"seq_length\",\n",
    "    # limit x to 100\n",
    "    #facet_row=\"attention_only\",\n",
    "    #title=f\"n_layer={filter_dic['n_layer']}, n_head={filter_dic['n_head']}, lr={filter_dic['lr']}, n_embd={filter_dic['n_embd']}\",\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()\n",
    "# log scale on y-axis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(15 / 128) * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "df_box = df_plot.copy()\n",
    "df_box = df_box[df_box[\"epoch\"] == 127]\n",
    "#df_box = df_box[np.isin(df_box[\"length_scale\"], [\"[1.0]\", \"[2.0]\"])]\n",
    "df_box[\"rmse_test\"] = np.sqrt(df_box[\"test_loss\"])\n",
    "fig = px.box(\n",
    "    df_box,\n",
    "    y = \"embedding_kernel_length\",\n",
    "    x ='rmse_test',\n",
    "    log_x=True,\n",
    "    color='embedding',\n",
    "    hover_data=df_plot.columns,\n",
    "    #facet_row=\"length_scale\",\n",
    "    facet_row=\"holes\",\n",
    "    #facet_row=\"parametrize_std\",\n",
    "    height=1500,\n",
    "    # set order on holes\n",
    "    category_orders={\"holes\": [\"{}\", \"[(0, 1), (2, 3), (4, 5), (6, 7), (8, 9)]\", \"[(3, 7)]\"]},\n",
    "    # show std\n",
    "    #error_y=\"std\",\n",
    "    # transparent\n",
    "\n",
    "    # don't share y-axes\n",
    "\n",
    "    \n",
    "    #facet_row=\"seq_length\",\n",
    "    # limit x to 100\n",
    "    #facet_row=\"attention_only\",\n",
    "    #title=f\"n_layer={filter_dic['n_layer']}, n_head={filter_dic['n_head']}, lr={filter_dic['lr']}, n_embd={filter_dic['n_embd']}\",\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()\n",
    "# log scale on y-axis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_box[\"length_scale\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "results_to_plot = df_plot.copy()\n",
    "results_to_plot[\"epoch\"] = results_to_plot[\"epoch\"].astype(float)\n",
    "#results_to_plot[\"test_loss\"] = np.sqrt(results_to_plot[\"test_loss\"]) # for rmse #TODO\n",
    "filter_dic = {\n",
    "    #\"holes\": \"{}\",\n",
    "    #\"fourier_length_scale\": 0.1,\n",
    "    #\"fourier_length_scale\": \"0.0520833333333333\",\n",
    "    #\"gaussian_embedding_sd\": \"[0.052083333333333336]\",\n",
    "    #\"gaussian_embedding_sd\": 0.1,\n",
    "    #\"epoch\": \"30\",\n",
    "}\n",
    "\n",
    "# rename \"none\" embedding to \"linear\"\n",
    "results_to_plot[\"embedding\"] = results_to_plot[\"embedding\"].replace(\"none\", \"linear\")\n",
    "\n",
    "# allow missing or value in filter_dic\n",
    "for key, value in filter_dic.items():\n",
    "    results_to_plot = results_to_plot[np.isin(results_to_plot[key], [value, \"missing\"])]\n",
    "\n",
    "# if embedding is fourier, only keep \"fourier_length_scale\": \"0.0520833333333333\",\n",
    "results_to_plot = results_to_plot[(results_to_plot[\"embedding\"] != \"fourier\") | (results_to_plot[\"length_scale\"] == \"0.46875\")]\n",
    "# same for gaussian with \"[0.052083333333333336]\"\n",
    "results_to_plot = results_to_plot[(results_to_plot[\"embedding\"] != \"gaussian\") | (results_to_plot[\"length_scale\"] == \"[0.5859375]\")]\n",
    "\n",
    "# fix the palette for the colors\n",
    "palette = px.colors.qualitative.Plotly\n",
    "palette = np.array(palette)\n",
    "\n",
    "# remove gaussian embedding\n",
    "#results_to_plot = results_to_plot[results_to_plot[\"embedding_type\"] != \"gaussian\"]\n",
    "\n",
    "\n",
    "#group_cols = [\"epoch\", \"dim_feedforward\", \"dropout\", \"norm_first\", \"embedding_type\"]\n",
    "group_cols = results_to_plot.columns\n",
    "#group_cols.remove([\"loss_mlm\", \"loss_num\", \"loss_total\", \"iter\"])\n",
    "group_cols = [col for col in group_cols if col not in [\"train_loss\", \"test_loss\", \"epoch\"]]\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Define the threshold\n",
    "threshold = 0.1\n",
    "\n",
    "# Group by the specified columns and filter\n",
    "def min_epoch_below_threshold(group):\n",
    "    below_threshold = group[group['test_loss'] < threshold]\n",
    "    if not below_threshold.empty:\n",
    "        return below_threshold['epoch'].min()\n",
    "    return None  # Return None if no epochs are below the threshold\n",
    "\n",
    "# Group by the specified columns and apply the function\n",
    "#result = results_to_plot.groupby(group_cols).apply(min_epoch_below_threshold).reset_index()\n",
    "result = results_to_plot.groupby(group_cols).apply(lambda group: group[group['test_loss'] < threshold]['epoch'].min()).reset_index()\n",
    "\n",
    "# Rename the result column for clarity\n",
    "result.rename(columns={0: 'min_epoch_to_reach_threshold'}, inplace=True)\n",
    "result[\"threshold\"] = threshold\n",
    "\n",
    "# Display the result\n",
    "print(result)\n",
    "\n",
    "threshold = 0.01\n",
    "# Group by the specified columns and filter\n",
    "result2 = results_to_plot.groupby(group_cols).apply(lambda group: group[group['test_loss'] < threshold]['epoch'].min()).reset_index()\n",
    "\n",
    "# Rename the result column for clarity\n",
    "result2.rename(columns={0: 'min_epoch_to_reach_threshold'}, inplace=True)\n",
    "result2[\"threshold\"] = threshold\n",
    "\n",
    "threshold = 0.005\n",
    "# Group by the specified columns and filter\n",
    "result3 = results_to_plot.groupby(group_cols).apply(lambda group: group[group['test_loss'] < threshold]['epoch'].min()).reset_index()\n",
    "\n",
    "# Rename the result column for clarity\n",
    "result3.rename(columns={0: 'min_epoch_to_reach_threshold'}, inplace=True)\n",
    "result3[\"threshold\"] = threshold\n",
    "\n",
    "# Display the result\n",
    "#fig = px.scatter(result, x='min_epoch_to_reach_threshold', y=\"embedding_type\", title='Minimum epoch to reach threshold', height=900, color='min_epoch_to_reach_threshold', facet_col='dataset_path',\n",
    "#                 hover_data=result.columns)\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_to_plot.embedding.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the two results\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Ensure 'group_cols' are set correctly as per your earlier code\n",
    "group_cols = results_to_plot.columns\n",
    "group_cols = [col for col in group_cols if col not in [\"train_loss\", \"test_loss\", \"epoch\", \"min_epoch_to_reach_threshold\"]]\n",
    "\n",
    "# Merge results and results2 on group columns\n",
    "merged_results = pd.concat([result, result2, result3])\n",
    "# Calculate standard deviation, min, and max for the epoch columns\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming merged_results is already defined and contains the necessary columns\n",
    "\n",
    "# Calculate mean, std, min, and max grouped by 'embedding_type'\n",
    "grouped_stats = merged_results.groupby(['embedding', \"threshold\"]).agg({\n",
    "    'min_epoch_to_reach_threshold': ['mean', 'std', 'min', 'max'],\n",
    "}).reset_index().reset_index()\n",
    "\n",
    "# Flattening the column MultiIndex\n",
    "grouped_stats.columns = [''.join(col).strip() for col in grouped_stats.columns.values]\n",
    "\n",
    "\n",
    "\n",
    "# # Function to format the entries with mean (min-max)\n",
    "def format_entry(row):\n",
    "     return f\"{row['min_epoch_to_reach_thresholdmean']:.1f} ({row['min_epoch_to_reach_thresholdmin']}-{row['min_epoch_to_reach_thresholdmax']})\"\n",
    "\n",
    "    \n",
    "grouped_stats[\"formatted_min_epochs\"] = grouped_stats.apply(format_entry, axis=1)\n",
    "\n",
    "# pivot formatted_min_epochs by threshold\n",
    "grouped_stats = grouped_stats.pivot(index='embedding', columns='threshold', values='formatted_min_epochs').reset_index()\n",
    "\n",
    "# reorder and rename columns\n",
    "grouped_stats = grouped_stats[[\"embedding\", 0.1, 0.01, 0.005]]\n",
    "grouped_stats.columns = [\"Embedding\", \"MSE=0.1\", \"MSE=0.01\", \"MSE=0.005\"]\n",
    "\n",
    "# export to latex\n",
    "print(grouped_stats.to_latex(index=False, escape=False))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_stats.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_box[[\"n_layer\", \"n_head\", \"n_embd\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.line(\n",
    "    df_plot,\n",
    "    x='epoch',\n",
    "    y='test_loss',\n",
    "    log_y=True,\n",
    "    color='normalization',\n",
    "    hover_data=df_plot.columns,\n",
    "    facet_row=\"length_scale\",\n",
    "    facet_col=\"holes\",\n",
    "    #facet_row=\"parametrize_std\",\n",
    "    height=1500,\n",
    "    # show std\n",
    "    #error_y=\"std\",\n",
    "    # transparent\n",
    "\n",
    "    # don't share y-axes\n",
    "\n",
    "    \n",
    "    #facet_row=\"seq_length\",\n",
    "    # limit x to 100\n",
    "    #facet_row=\"attention_only\",\n",
    "    #title=f\"n_layer={filter_dic['n_layer']}, n_head={filter_dic['n_head']}, lr={filter_dic['lr']}, n_embd={filter_dic['n_embd']}\",\n",
    ")\n",
    "fig.show()\n",
    "# log scale on y-axis\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skrub",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
